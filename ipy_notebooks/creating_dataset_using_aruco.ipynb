{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import aruco\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "_pth = os.path.join(_pth, 'ArUco_detection', \"images\")\n",
    "image_list = os.listdir(_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "DICTIONARY = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_ORIGINAL)\n",
    "detector = aruco.ArucoDetector(DICTIONARY, ARUCO_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "raw_data_pth = os.path.join(raw_data_pth, 'dataset', \"raw_data\")\n",
    "if not os.path.exists(raw_data_pth):\n",
    "    os.makedirs(os.path.join(raw_data_pth, \"images\"))\n",
    "    os.makedirs(os.path.join(raw_data_pth, \"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1963/1963 [03:31<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name in tqdm(image_list):\n",
    "    _image_path = os.path.join(_pth, img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(image)\n",
    "    \n",
    "    if len(markerCorners) == 0:\n",
    "        continue\n",
    "    \n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"w\")\n",
    "    label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "    _markerCorners = markerCorners[0][0]\n",
    "    label_writer.writerow([\"0\", _markerCorners[0][0], _markerCorners[0][1], _markerCorners[1][0], _markerCorners[1][1], _markerCorners[2][0], _markerCorners[2][1], _markerCorners[3][0], _markerCorners[3][1], _markerCorners[0][0], _markerCorners[0][1]])\n",
    "    label_file.close()\n",
    "    \n",
    "    # save image\n",
    "    image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "    cv2.imwrite(image_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835 1963\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(os.path.join(raw_data_pth, \"labels\"))), len(image_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting it into traning and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1835/1835 [02:21<00:00, 12.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_pth = os.path.join(data_pth, 'dataset', \"dataset_processed\")\n",
    "\n",
    "train_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "train_data_pth = os.path.join(train_data_pth, 'dataset_processed', \"train\")\n",
    "validation_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "validation_data_pth = os.path.join(validation_data_pth, 'dataset_processed', \"val\")\n",
    "test_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "test_data_pth = os.path.join(test_data_pth, 'dataset_processed', \"test\")\n",
    "\n",
    "if not os.path.exists(train_data_pth):\n",
    "    os.makedirs(os.path.join(train_data_pth, \"images\"))\n",
    "    os.makedirs(os.path.join(train_data_pth, \"labels\"))\n",
    "\n",
    "if not os.path.exists(test_data_pth):\n",
    "    os.makedirs(os.path.join(test_data_pth, \"images\"))\n",
    "    os.makedirs(os.path.join(test_data_pth, \"labels\"))\n",
    "    \n",
    "if not os.path.exists(validation_data_pth):\n",
    "    os.makedirs(os.path.join(validation_data_pth, \"images\"))\n",
    "    os.makedirs(os.path.join(validation_data_pth, \"labels\"))\n",
    "    \n",
    "image_list = os.listdir(os.path.join(raw_data_pth, \"images\"))\n",
    "\n",
    "# splitting dataset into train and test\n",
    "for img_name in tqdm(image_list):\n",
    "    \n",
    "    _image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    \n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\")\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "    label = list(label_reader)[0]\n",
    "    label_file.close()\n",
    "    \n",
    "    if int(label[0]) == 0:\n",
    "        if np.random.rand() < 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(train_data_pth, \"images\", img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(train_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(validation_data_pth, \"images\", img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(validation_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        else:\n",
    "            # save image\n",
    "            image_path = os.path.join(test_data_pth, \"images\", img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(test_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1835/1835 [02:39<00:00, 11.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_pth = os.path.join(data_pth, 'dataset', \"dataset_processed\")\n",
    "\n",
    "images_pth = os.path.join(data_pth, \"images\")\n",
    "labels_pth = os.path.join(data_pth, \"labels\")\n",
    "\n",
    "if not os.path.exists(images_pth):\n",
    "    os.makedirs(os.path.join(images_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"test\"))\n",
    "\n",
    "if not os.path.exists(labels_pth):\n",
    "    os.makedirs(os.path.join(labels_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"test\"))\n",
    "    \n",
    "    \n",
    "image_list = os.listdir(os.path.join(raw_data_pth, \"images\"))\n",
    "\n",
    "# splitting dataset into train and test\n",
    "for img_name in tqdm(image_list):\n",
    "    \n",
    "    _image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    \n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\")\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "    label = list(label_reader)[0]\n",
    "    label_file.close()\n",
    "    \n",
    "    if int(label[0]) == 0:\n",
    "        if np.random.rand() < 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"train\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"train\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"val\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"val\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        else:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"test\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"test\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
