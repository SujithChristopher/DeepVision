{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.yolo.utils.benchmarks import benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x128 (no detections), 324.1ms\n",
      "Speed: 0.0ms preprocess, 324.1ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 128)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for PyTorch: shape '[90, 17, -1]' is invalid for input of size 900\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1+cu118...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.4s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.torchscript (12.1 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.torchscript imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.torchscript imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.torchscript for TorchScript inference...\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x160 (no detections), 364.8ms\n",
      "Speed: 0.0ms preprocess, 364.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 160)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.torchscript for TorchScript inference...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for TorchScript: shape '[66, 17, -1]' is invalid for input of size 660\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "WARNING  half=True only compatible with GPU export, i.e. use device=0\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx (11.8 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx for ONNX Runtime inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x160 (no detections), 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 160)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx for ONNX Runtime inference...\n",
      "Forcing batch=1 square inference (1,3,160,160) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for ONNX: shape '[66, 17, -1]' is invalid for input of size 660\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.1s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx (11.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino-dev>=2022.3'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting openvino-dev>=2022.3\n",
      "  Downloading openvino_dev-2023.0.1-11005-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 538.1 kB/s eta 0:00:00\n",
      "Collecting addict>=2.4.0 (from openvino-dev>=2022.3)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (0.7.1)\n",
      "Collecting jstyleson>=0.0.2 (from openvino-dev>=2022.3)\n",
      "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting networkx<=2.8.8 (from openvino-dev>=2022.3)\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 700.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (1.24.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (4.8.0.74)\n",
      "Collecting openvino-telemetry>=2022.1.0 (from openvino-dev>=2022.3)\n",
      "  Downloading openvino_telemetry-2023.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pillow>=8.1.2 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (10.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (6.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (2.28.1)\n",
      "Collecting texttable>=1.6.3 (from openvino-dev>=2022.3)\n",
      "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (4.65.0)\n",
      "Collecting openvino==2023.0.1 (from openvino-dev>=2022.3)\n",
      "  Downloading openvino-2023.0.1-11005-cp310-cp310-win_amd64.whl (27.2 MB)\n",
      "     -------------------------------------- 27.2/27.2 MB 634.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from openvino-dev>=2022.3) (1.11.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from tqdm>=4.54.1->openvino-dev>=2022.3) (0.4.6)\n",
      "Building wheels for collected packages: jstyleson\n",
      "  Building wheel for jstyleson (setup.py): started\n",
      "  Building wheel for jstyleson (setup.py): finished with status 'done'\n",
      "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2392 sha256=8e8792b88963e09d3257301c634bfcb4e3f78fc8895c432575c65d2e93842bd7\n",
      "  Stored in directory: C:\\Users\\Pintu\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2rqe8xaw\\wheels\\12\\51\\c6\\a1e751db88203e11c6d9ffe4683ca3d8c14b1479639bec1006\n",
      "Successfully built jstyleson\n",
      "Installing collected packages: texttable, openvino-telemetry, jstyleson, addict, openvino, networkx, openvino-dev\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.0\n",
      "    Uninstalling networkx-3.0:\n",
      "      Successfully uninstalled networkx-3.0\n",
      "Successfully installed addict-2.4.0 jstyleson-0.0.2 networkx-2.8.8 openvino-2023.0.1 openvino-dev-2023.0.1 openvino-telemetry-2023.0.0 texttable-1.6.7\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  169.3s, installed 1 package: ['openvino-dev>=2022.3']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.0.1-11005-fa1c41994f3-releases/2023/0...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  178.8s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_openvino_model\\ (6.2 MB)\n",
      "\n",
      "Export complete (180.2s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_openvino_model imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_openvino_model imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_openvino_model for OpenVINO inference...\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x160 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 160)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_openvino_model for OpenVINO inference...\n",
      "Forcing batch=1 square inference (1,3,160,160) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for OpenVINO: shape '[66, 17, -1]' is invalid for input of size 660\n",
      "ERROR  Benchmark failure for TensorRT: inference not supported on CPU\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['coremltools>=6.0'] not found, attempting AutoUpdate...\n",
      "Collecting coremltools>=6.0\n",
      "  Downloading coremltools-6.3.0.tar.gz (941 kB)\n",
      "     ------------------------------------ 941.9/941.9 kB 324.1 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from coremltools>=6.0) (1.24.3)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from coremltools>=6.0) (3.20.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from coremltools>=6.0) (1.11.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from coremltools>=6.0) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from coremltools>=6.0) (23.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from sympy->coremltools>=6.0) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from tqdm->coremltools>=6.0) (0.4.6)\n",
      "Building wheels for collected packages: coremltools\n",
      "  Building wheel for coremltools (setup.py): started\n",
      "  Building wheel for coremltools (setup.py): finished with status 'done'\n",
      "  Created wheel for coremltools: filename=coremltools-6.3.0-py3-none-any.whl size=1220331 sha256=fbec3ee2df16c847e645c04518c038833f7c068f15eff0b5fa6fb484bb3858f7\n",
      "  Stored in directory: C:\\Users\\Pintu\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-r9k83xar\\wheels\\2d\\73\\aa\\54e0385c02dffa25b85eaeab8b298997fea0b48da7daa91a21\n",
      "Successfully built coremltools\n",
      "Installing collected packages: coremltools\n",
      "Successfully installed coremltools-6.3.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  92.0s, installed 1 package: ['coremltools>=6.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "TensorFlow version 2.13.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Torch version 2.0.1+cu118 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 6.3.0...\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 670/671 [00:00<00:00, 1255.03 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 100.88 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 56/56 [00:01<00:00, 39.05 passes/s] \n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 8/8 [00:00<00:00, 225.01 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops:  87%|████████▋ | 637/734 [00:00<00:00, 1020.72 ops/s]Const anchor_points was already added.\n",
      "Const 673 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 734/734 [00:00<00:00, 1078.32 ops/s]\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['scikit-learn'] not found, attempting AutoUpdate...\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 284.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\pintu\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------ 302.0/302.0 kB 396.9 kB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.1 scikit-learn-1.3.0 threadpoolctl-3.1.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  80.7s, installed 1 package: ['scikit-learn']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m export failure  181.2s: scikit-learn is required for k-means quantization. To install, run: \"pip install -U scikit-learn\".\n",
      "ERROR  Benchmark failure for CoreML: '[]' does not exist\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using kmeans_lut quantization\n",
      "Optimizing Neural Network before Quantization:\n",
      "Finished optimizing network. Quantizing neural network..\n",
      "Quantizing layer input.1 of type convolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  7.6s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx (11.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx -o D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model -nuo --non_verbose -oiqt -qt per-tensor'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  158.5s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model (39.2 MB)\n",
      "\n",
      "Export complete (158.9s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model for TensorFlow SavedModel inference...\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x160 (no detections), 932.4ms\n",
      "Speed: 0.0ms preprocess, 932.4ms inference, 5.2ms postprocess per image at shape (1, 3, 160, 160)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model for TensorFlow SavedModel inference...\n",
      "Forcing batch=1 square inference (1,3,160,160) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for TensorFlow SavedModel: shape '[66, 17, -1]' is invalid for input of size 660\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  8.2s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx (11.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx -o D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model -nuo --non_verbose -oiqt -qt per-tensor'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  87.8s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model (39.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export failure  0.0s: '_UserObject' object has no attribute 'inputs'\n",
      "\n",
      "Export complete (88.1s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "ERROR  Benchmark failure for TensorFlow GraphDef: export failed\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  3.9s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx (11.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.onnx -o D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model -nuo --non_verbose -oiqt -qt per-tensor'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  80.3s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model (39.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model\\best_int8.tflite (3.0 MB)\n",
      "\n",
      "Export complete (80.7s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model\\best_int8.tflite imgsz=160 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model\\best_int8.tflite imgsz=160 data=../dataset/multi_class/dataset_processed/dataset.yaml \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model\\best_int8.tflite for TensorFlow Lite inference...\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\anaconda3\\envs\\py310\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 160x160 (no detections), 76.2ms\n",
      "Speed: 0.0ms preprocess, 76.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 160)\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "Loading D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best_saved_model\\best_int8.tflite for TensorFlow Lite inference...\n",
      "Forcing batch=1 square inference (1,3,160,160) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\ipy_notebooks\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "ERROR  Benchmark failure for TensorFlow Lite: shape '[65, 17, -1]' is invalid for input of size 650\n",
      "ERROR  Benchmark failure for TensorFlow Edge TPU: Edge TPU export only supported on Linux\n",
      "ERROR  Benchmark failure for TensorFlow.js: TF.js export only supported on macOS and Linux\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.12 torch-2.0.1+cu118 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt with input shape (1, 3, 160, 160) BCHW and output shape(s) (1, 17, 525) (6.1 MB)\n",
      "WARNING: OMP_NUM_THREADS set to 24, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\n",
      "PLEASE USE OMP_NUM_THREADS WISELY.\n",
      "\n",
      "\u001b[34m\u001b[1mPaddlePaddle:\u001b[0m starting export with X2Paddle 1.4.1...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "benchmark(model=r\"D:\\CMC\\DeepVision\\ipy_notebooks\\runs\\pose\\train6\\weights\\best.pt\", half=True, int8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
